import streamlit as st
import requests
import random
import re
import itertools
import urllib3
import time
import urllib.parse
import google.generativeai as genai
from collections import Counter
from bs4 import BeautifulSoup

# 1. åŸºç¤è¨­å®š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å˜—è©¦åŒ¯å…¥ BeautifulSoup
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False

# ==========================================
# ğŸ”‘ API é‡‘é‘°è¨­å®šå€
# ==========================================
GEMINI_API_KEY = "AIzaSyACLssBFMWfLpIprNmx7TdQe_k4k4JCLEM"
WEATHER_API_KEY = "E3e2c14f7956d939b88a6dfa66e4f10a"

# ==========================================
# ğŸ” æ ¸å¿ƒ 1: æ™ºèƒ½æœå°‹
# ==========================================
class WebSearcher:
    @staticmethod
    def decode_ddg_url(raw_url):
        try:
            if raw_data := re.search(r'uddg=([^&]+)', raw_url):
                return urllib.parse.unquote(raw_data.group(1))
            return raw_url if raw_url.startswith('http') else ""
        except: return ""

    @staticmethod
    def search_wiki(query):
        try:
            url = "https://zh.wikipedia.org/w/api.php"
            params = {"action": "query", "format": "json", "list": "search", "srsearch": query, "srlimit": 3}
            res = requests.get(url, params=params, timeout=5)
            data = res.json()
            results = []
            if "query" in data and "search" in data["query"]:
                for item in data["query"]["search"]:
                    title = item["title"]
                    snippet = re.sub(r'<[^>]+>', '', item["snippet"])
                    link = f"https://zh.wikipedia.org/wiki/{title}"
                    results.append({"title": f"ğŸ“š [ç¶­åŸº] {title}", "link": link, "snippet": snippet})
            return results
        except: return []

    @staticmethod
    def search_advanced(query, model):
        try:
            url = f"https://html.duckduckgo.com/html/?q={query}"
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
            res = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            results_list = []
            snippets_text = []

            # Wiki
            wiki_res = WebSearcher.search_wiki(query)
            results_list.extend(wiki_res)
            for w in wiki_res: snippets_text.append(f"{w['title']}: {w['snippet']}")

            # DDG
            for i, result in enumerate(soup.find_all('div', class_='result'), 1):
                if i > 8: break 
                title_tag = result.find('a', class_='result__a')
                snippet_tag = result.find('a', class_='result__snippet')
                
                if title_tag:
                    title = title_tag.get_text().strip()
                    raw_link = title_tag['href']
                    real_link = WebSearcher.decode_ddg_url(raw_link)
                    snippet = snippet_tag.get_text().strip() if snippet_tag else ""
                    
                    if real_link:
                        results_list.append({"title": title, "link": real_link, "snippet": snippet})
                        snippets_text.append(f"æ¨™é¡Œï¼š{title}\næ‘˜è¦ï¼š{snippet}")

            # AI ç¸½çµ
            raw_data = "\n\n".join(snippets_text[:6])
            ai_summary = "âŒ æœå°‹ç„¡çµæœã€‚"
            
            if raw_data:
                if model:
                    prompt = f"è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”ï¼šã€{query}ã€\nè³‡æ–™ï¼š{raw_data}\nè«‹ç›´æ¥çµ¦å‡ºé‡é»ç­”æ¡ˆï¼ˆæ—¥æœŸã€æ•¸å­—ï¼‰ï¼Œä¸è¦åˆ—å‡ºç¶²å€ã€‚"
                    try:
                        ai_resp = model.generate_content(prompt)
                        ai_summary = ai_resp.text
                    except:
                        ai_summary = f"**æœå°‹æ‘˜è¦ (AI å¿™ç·š)**ï¼š\n{raw_data[:500]}..."
                else:
                    ai_summary = f"**æœå°‹æ‘˜è¦**ï¼š\n{raw_data[:500]}..."
            
            return ai_summary, results_list
        except Exception as e: return f"âš ï¸ æœå°‹éŒ¯èª¤: {e}", []

# ==========================================
# ğŸ° æ ¸å¿ƒ 2: è³“æœ/æ¨‚é€ (1ä»£ç®—æ³•)
# ==========================================
class LottoAlgorithm:
    @staticmethod
    def calculate_ac(numbers):
        r = len(numbers)
        diffs = set()
        for pair in itertools.combinations(numbers, 2): diffs.add(abs(pair[0] - pair[1]))
        return len(diffs) - (r - 1)
    @staticmethod
    def is_prime(n):
        if n < 2: return False
        for i in range(2, int(n**0.5) + 1):
            if n % i == 0: return False
        return True
    @staticmethod
    def predict(l_type):
        if "å¤§æ¨‚é€" in l_type or "å¤§ç†±é€" in l_type: max_n, pick, min_ac = 49, 6, 7
        elif "å¨åŠ›" in l_type: max_n, pick, min_ac = 38, 6, 7
        elif "539" in l_type: max_n, pick, min_ac = 39, 5, 4
        else: return "âš ï¸ æœªçŸ¥å½©ç¨®", []

        primes = [n for n in range(1, max_n+1) if LottoAlgorithm.is_prime(n)]
        best_combo = None
        for _ in range(5000):
            combo = sorted(random.sample(range(1, max_n+1), pick))
            if LottoAlgorithm.calculate_ac(combo) < min_ac: continue
            p_cnt = sum(1 for n in combo if n in primes)
            if not (1 <= p_cnt <= 3): continue
            best_combo = combo
            break
        if not best_combo: best_combo = sorted(random.sample(range(1, max_n+1), pick))
        
        special = f" + ç¬¬äºŒå€ [{random.randint(1,8):02d}]" if "å¨åŠ›" in l_type else ""
        return f"ğŸ° **{l_type.replace('ç†±','æ¨‚')} é æ¸¬**\n\nğŸ”¢ **{best_combo}** {special}\n\nğŸ“Š ACå€¼ï¼š{LottoAlgorithm.calculate_ac(best_combo)}", []

class BingoAlgorithm:
    @staticmethod
    def analyze_and_predict(stars=5):
        if not HAS_BS4: return "âš ï¸ è«‹å…ˆå®‰è£ bs4", []
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
            url = "https://www.pilio.idv.tw/bingo/list.asp"
            res = requests.get(url, headers=headers, timeout=10, verify=False)
            res.encoding = 'big5'
            soup = BeautifulSoup(res.text, 'html.parser')
            all_numbers = []
            for row in soup.find_all('tr'):
                text = row.get_text(strip=True)
                if re.search(r'11[3-9]\d{6}', text) or re.search(r'11[0-2]\d{6}', text): 
                    nums = [int(n) for n in re.findall(r'\d+', text) if int(n) <= 80][:20]
                    if len(nums) == 20: all_numbers.extend(nums)
            
            if not all_numbers: return "âŒ è³“æœç¶²ç«™é˜»æ“‹", []
            counts = Counter(all_numbers)
            hot_numbers = counts.most_common(stars)
            prediction = sorted([num for num, count in hot_numbers])
            return f"ğŸ± **è³“æœ {stars} æ˜Ÿé æ¸¬ (è¿½ç†±)**\n\nğŸ”¥ æ¨è–¦ï¼š**{prediction}**", []
        except Exception as e: return f"âš ï¸ è³“æœéŒ¯èª¤: {e}", []

    @staticmethod
    def get_latest():
        return "ğŸ“¢ è«‹æŸ¥çœ‹å³å´æœå°‹é¢æ¿", []

# ==========================================
# ğŸ“ˆ æ ¸å¿ƒ 3: è²¡ç¶“/å¤©æ°£
# ==========================================
class DirectInfo:
    @staticmethod
    def get_stock(code):
        try:
            ts = int(time.time() * 1000)
            url = f"https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_{code}.tw|otc_{code}.tw&json=1&_={ts}"
            res = requests.get(url, timeout=5, verify=False)
            data = res.json()
            if 'msgArray' in data and data['msgArray']:
                i = data['msgArray'][0]
                p = i.get('z', '-')
                if p == '-': p = i.get('b', '-').split('_')[0]
                diff_val = float(p) - float(i.get('y', 0)) if p != '-' and i.get('y') != '-' else 0
                color = "red" if diff_val > 0 else "green" if diff_val < 0 else "grey"
                return f"ğŸ“ˆ **å°è‚¡ {code} {i.get('n',code)}**\n\nğŸ’° ç¾åƒ¹ï¼š**{p}**\nğŸ“Š æ˜¨æ”¶ï¼š{i.get('y','-')}\nğŸ”¥ æ¼²è·Œï¼š:{color}[{diff_val:.2f}]", []
            return "âš ï¸ æŸ¥ç„¡ä»£ç¢¼", []
        except: return "âš ï¸ è‚¡åƒ¹å¿™ç·š", []

    @staticmethod
    def get_weather(city):
        try:
            city_map = {"å°åŒ—": "Taipei", "å°å—": "Tainan", "å°ä¸­": "Taichung", "é«˜é›„": "Kaohsiung"}
            q = city_map.get(city.replace("å°","è‡º"), city)
            if q == city: q = city_map.get(city.replace("è‡º","å°"), city)
            url = "http://api.openweathermap.org/data/2.5/weather"
            params = {'q': q, 'appid': WEATHER_API_KEY, 'units': 'metric', 'lang': 'zh_tw'}
            r = requests.get(url, params=params, timeout=5)
            if r.status_code == 200:
                d = r.json()
                return f"ğŸ“ **{d['name']}**\n\nğŸŒ¡ï¸ {d['main']['temp']}Â°C\nâ˜ï¸ {d['weather'][0]['description']}", []
            return "âŒ æŸ¥ç„¡åŸå¸‚", []
        except: return "âš ï¸ å¤©æ°£éŒ¯èª¤", []

# ==========================================
# ğŸ§  è³ˆç¶­æ–¯å¤§è…¦ (é‚è¼¯ä¿®å¾©)
# ==========================================
def get_ai_model():
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        avail = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target = 'gemini-1.5-flash' if 'models/gemini-1.5-flash' in avail else 'gemini-pro'
        return genai.GenerativeModel(target), target
    except:
        return None, "é›¢ç·š"

def jarvis_think(text, model):
    raw = text
    text = text.lower()
    
    # ğŸŸ¢ ä¿®æ­£ï¼šåŠ å…¥ä¸­æ–‡æ•¸å­—å°ç…§è¡¨
    cn_num = {'ä¸€':1, 'äºŒ':2, 'ä¸‰':3, 'å››':4, 'äº”':5, 'å…­':6, 'ä¸ƒ':7, 'å…«':8, 'ä¹':9, 'å':10}

    # 1. è³“æœ/æ¨‚é€
    if "é æ¸¬" in text or "ç®—ç‰Œ" in text or "è³“æœ" in text:
        if "å¤§æ¨‚é€" in text or "å¤§ç†±é€" in text: return LottoAlgorithm.predict("å¤§æ¨‚é€")
        if "å¨åŠ›" in text: return LottoAlgorithm.predict("å¨åŠ›å½©")
        if "539" in text: return LottoAlgorithm.predict("539")
        
        # é è¨­ 5 æ˜Ÿ
        stars = 5
        
        # ğŸŸ¢ é‚è¼¯ 1: æª¢æŸ¥ä¸­æ–‡æ•¸å­— (ä¸€æ˜Ÿ~åæ˜Ÿ)
        for k, v in cn_num.items(): 
            if f"{k}æ˜Ÿ" in text or f"{k} æ˜Ÿ" in text: 
                stars = v
                break
        
        # ğŸŸ¢ é‚è¼¯ 2: æª¢æŸ¥é˜¿æ‹‰ä¼¯æ•¸å­— (å„ªå…ˆæ¬Šè¼ƒé«˜ï¼Œè¦†è“‹ä¸­æ–‡)
        m = re.search(r'(\d+)\s*æ˜Ÿ', text)
        if m: stars = int(m.group(1))
        
        return BingoAlgorithm.analyze_and_predict(stars)

    # 2. è‚¡åƒ¹/å¤©æ°£
    if "è‚¡" in text and re.search(r'\d{4,6}', text):
        return DirectInfo.get_stock(re.search(r'\d{4,6}', text).group(0))
    if "å¤©æ°£" in text:
        return DirectInfo.get_weather(text.replace("å¤©æ°£","").strip() or "å°å—")

    # 3. æ™ºèƒ½æœå°‹
    search_triggers = ["æ™‚é–“", "æ—¥æœŸ", "æ–°è", "å ±å", "å ±è€ƒ", "å¹¾é»", "ä»€éº¼æ™‚å€™", "æ˜¯èª°", "å¤šå°‘éŒ¢", "æœå°‹", "æŸ¥"]
    if any(k in text for k in search_triggers) or (model and len(text) > 4):
        return WebSearcher.search_advanced(raw, model)

    # 4. é–’èŠ
    if model:
        try: return model.generate_content(raw).text, []
        except: pass
    
    return "ğŸ¤– è«‹è¼¸å…¥æ˜ç¢ºæŒ‡ä»¤", []

# ==========================================
# ğŸŒ Streamlit ç¶²é ä»‹é¢
# ==========================================
st.set_page_config(page_title="Jarvis Web", layout="wide", page_icon="ğŸ¤–")

if "history" not in st.session_state:
    st.session_state.history = []
if "search_results" not in st.session_state:
    st.session_state.search_results = []
if "model" not in st.session_state:
    model, name = get_ai_model()
    st.session_state.model = model
    st.session_state.model_name = name

st.markdown("""
<style>
    .reportview-container { margin-top: -2em; }
    .stDeployButton {display:none;}
    #MainMenu {visibility: hidden;}
    a {text-decoration: none; color: #3498db !important; font-weight: bold;}
    a:hover {text-decoration: underline; color: #63cdda !important;}
    .search-card {
        background-color: #262730;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 10px;
        border: 1px solid #333;
    }
</style>
""", unsafe_allow_html=True)

col_head1, col_head2 = st.columns([8, 2])
with col_head1:
    st.title("ğŸ¤– Jarvis Web OS")
with col_head2:
    st.success(f"AI: {st.session_state.model_name}")

col_chat, col_feed = st.columns([7, 3])

with col_chat:
    chat_container = st.container(height=600)
    for msg in st.session_state.history:
        with chat_container.chat_message(msg["role"]):
            st.markdown(msg["content"])
            
    if prompt := st.chat_input("è¼¸å…¥æŒ‡ä»¤ (å¦‚: è³“æœä¸‰æ˜Ÿ / 2026äº”å°ˆå ±å / 00919è‚¡åƒ¹)..."):
        st.session_state.history.append({"role": "user", "content": prompt})
        with chat_container.chat_message("user"):
            st.write(prompt)
            
        with chat_container.chat_message("assistant"):
            with st.spinner("Jarvis æ­£åœ¨é‹ç®—..."):
                reply, s_results = jarvis_think(prompt, st.session_state.model)
                st.markdown(reply)
                
        st.session_state.history.append({"role": "assistant", "content": reply})
        st.session_state.search_results = s_results
        st.rerun()

with col_feed:
    st.subheader("ğŸŒ å³æ™‚è³‡è¨Šæµ")
    if not st.session_state.search_results:
        st.info("å°šç„¡å¤–éƒ¨è³‡è¨Šï¼Œè«‹å˜—è©¦æœå°‹ç›¸é—œå•é¡Œã€‚")
    else:
        for item in st.session_state.search_results:
            st.markdown(f"""
            <div class="search-card">
                <a href="{item['link']}" target="_blank" style="font-size: 16px;">
                    {item['title']}
                </a>
                <p style="color: #bbb; font-size: 13px; margin-top: 5px;">
                    {item['snippet']}
                </p>
            </div>
            """, unsafe_allow_html=True)